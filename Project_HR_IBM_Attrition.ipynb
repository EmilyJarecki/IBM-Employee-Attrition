{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilyJarecki/IBM-Employee-Attrition/blob/main/Project_HR_IBM_Attrition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycaret"
      ],
      "metadata": {
        "id": "wdBkq49R5-Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0CFld51GVrj"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "from sklearn import set_config\n",
        "\n",
        "#PyCaret\n",
        "from pycaret.classification import *\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zC-vKoArGhY6"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdY0y1ZXmxnD"
      },
      "source": [
        "### 1. Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNtYBoYVGpYw"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "data = pd.read_excel(io.BytesIO(uploaded[\n",
        "    'IBM HR Employe Attrition Sample Data.xlsx']),header=0)\n",
        "\n",
        "data = pd.read_excel('IBM HR Employe Attrition Sample Data.xlsx')\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXhf7ydwZYOk"
      },
      "source": [
        "### 2. Set up the Pycaret environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEjgiepWXGuX"
      },
      "outputs": [],
      "source": [
        "# remove unnecessary columns\n",
        "\n",
        "data = data.drop(columns=['EmployeeNumber', 'EmployeeCount',\n",
        "                          'Over18', 'StandardHours', 'DailyRate',\n",
        "                          'HourlyRate', 'MonthlyRate'])\n",
        "\n",
        "\n",
        "clf1 = setup(data, target = 'Attrition', session_id=786)\n",
        "\n",
        "\n",
        "# setup() handles encoding\n",
        "# A lot of data cleaning is done here\n",
        "# splits into 80/20\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Exploration"
      ],
      "metadata": {
        "id": "pzypqyPNdt8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Attrition Count\n",
        "sns.countplot(data, x='Attrition', palette='winter')\n",
        "plt.title('Attrition Count')\n",
        "plt.show()\n",
        "\n",
        "data['Attrition'].value_counts(normalize=True) * 100\n"
      ],
      "metadata": {
        "id": "IO7lK4BbdsMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 Monthly Income by Attrition\n",
        "sns.boxplot(data, x='Attrition', y='MonthlyIncome', palette='magma')\n",
        "plt.title('Monthly Income by Attrition')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "azB4gEOreghO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Distribution of Age by Attrition\n",
        "sns.histplot(data, x='Age', hue='Attrition', kde=True, palette='mako')\n",
        "plt.title('Distribution of Age by Attrition')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PyH6TCIcgI4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4 Job Level vs. Attrition\n",
        "sns.countplot(data, x='JobLevel', hue='Attrition', palette='rocket')\n",
        "plt.title('Attrition by Job Level')\n",
        "plt.show()\n",
        "\n",
        "# Group by JobLevel and Attrition and count\n",
        "counts = data.groupby(['JobLevel', 'Attrition']).size().reset_index(name='Count')\n",
        "\n",
        "# Calculate percentage within each JobLevel\n",
        "# Instead of direct assignment, use transform to align indices\n",
        "counts['Percentage'] = counts.groupby('JobLevel')['Count'].transform(lambda x: x / x.sum() * 100)\n",
        "print(counts)"
      ],
      "metadata": {
        "id": "F-ttVNI4kSHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5 Department vs Attrition\n",
        "sns.countplot(data, x='Department', hue='Attrition', palette='tab10')\n",
        "plt.title('Attrition by Department')\n",
        "plt.xticks(rotation=20)\n",
        "plt.show()\n",
        "\n",
        "dept_attrition_matrix = pd.crosstab(data['Department'], data['Attrition'])\n",
        "\n",
        "print()\n",
        "print(\"------------WHOLE NUMBERS-----------\")\n",
        "print(dept_attrition_matrix)\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(\"-------------PERCENTAGE-------------\")\n",
        "dept_attrition_pct = pd.crosstab(data['Department'], data['Attrition'], normalize='index') * 100\n",
        "\n",
        "print(dept_attrition_pct.round(2))"
      ],
      "metadata": {
        "id": "ZKCSTz-Hkmuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode target variable if necessary\n",
        "data['Attrition_Encoded'] = data['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Heatmap\n",
        "plt.figure(figsize=(20, 12))\n",
        "sns.heatmap(data.corr(numeric_only=True), annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "FOKYsHQYYNb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnKYrjZXnBT_"
      },
      "source": [
        "### 3. Compare Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCDRnZS6aeDB"
      },
      "outputs": [],
      "source": [
        "compare_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gcU5cYPnFKy"
      },
      "source": [
        "### 4. Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HVLgjR5llsb"
      },
      "outputs": [],
      "source": [
        "lr_model = create_model('lr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWfU8qlrnOBS"
      },
      "source": [
        "### 5. Tune Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87efqvebnRah"
      },
      "outputs": [],
      "source": [
        "tuned_lr = tune_model(lr_model, n_iter=50, optimize = 'AUC')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1miQxjFAxR0"
      },
      "outputs": [],
      "source": [
        "print(\"Logistic Regresison model:\")\n",
        "print(lr_model)\n",
        "print()\n",
        "print()\n",
        "print(\"Tuned Logistic Regression Model: \")\n",
        "print(tuned_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GouBdKL9Btnh"
      },
      "source": [
        "### 6. Ensemble Model\n",
        "Ensembling is the process of combining predictions from multiple machine learning models to create a stronger, more robust model.\n",
        "\n",
        "Think of it like this: instead of relying on one \"expert\" (a single model), you ask several experts and average or vote on their answers. This tends to improve accuracy and reduce overfitting.\n",
        "\n",
        "The ensemble model types are:\n",
        "* Bagging\n",
        "<br>\n",
        "* Boosting\n",
        "<br>\n",
        "* Blending/Stacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGlw5JenBEqa"
      },
      "outputs": [],
      "source": [
        "bagged_lr = ensemble_model(tuned_lr, n_estimators=50)\n",
        "\n",
        "print(bagged_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpggNZ6NrIpf"
      },
      "outputs": [],
      "source": [
        "boosted_lr = ensemble_model(tuned_lr, method = 'Boosting')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36EvmNq5ItQg"
      },
      "source": [
        "### 7. Blend Models\n",
        "To get maximum value out of blending, we want to mix diverse models.\n",
        "<br>\n",
        "Random Forest and Gradient Boosting will capture complex interactions, while Logistic Regression will focus on linear relationships. K-Nearest Neighbors will help make predictions based on proximity to other data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AXg-ibZeIwCx"
      },
      "outputs": [],
      "source": [
        "rf_model = create_model('rf')\n",
        "xgb_model = create_model('xgboost')\n",
        "knn_model = create_model('knn')\n",
        "\n",
        "blended = blend_models(estimator_list = [tuned_lr, rf_model, xgb_model, knn_model])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_etQQhxMpcF"
      },
      "source": [
        "### 8. Analyze Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.corr(numeric_only=True)['MonthlyIncome'].sort_values(ascending=False)\n"
      ],
      "metadata": {
        "id": "HOck0kxce_vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzzx2s4rrz7l"
      },
      "outputs": [],
      "source": [
        "evaluate_model(tuned_lr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(tuned_lr, plot = 'auc')"
      ],
      "metadata": {
        "id": "DMMCR-rAS5x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(tuned_lr, plot = 'confusion_matrix')"
      ],
      "metadata": {
        "id": "ZAesnQQMTB5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hUqfv_wP4zQ"
      },
      "source": [
        "### 9. Interpret Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8ohIr2PU2Xa"
      },
      "source": [
        "My notes: XGBoost has built-in SHAP. This plot uses SHAP values to analyze the relationships between features and the target variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjZrVFebP94x"
      },
      "outputs": [],
      "source": [
        "interpret_model(xgb_model)\n",
        "\n",
        "\n",
        "\n",
        "# the interpret_model function only supports tree based models\n",
        "# IT HANDLES MULTICOLLINEARITY BETTER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk3h4OL5Vqrg"
      },
      "outputs": [],
      "source": [
        "interpret_model(xgb_model, plot = 'correlation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9bTCzXUVvVO"
      },
      "outputs": [],
      "source": [
        "interpret_model(xgb_model, plot = 'reason', observation=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC2P5CXyJbXL"
      },
      "source": [
        "### 10. Predict Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi02wt-m_weT"
      },
      "source": [
        "This is finally testing the predictive model created on the testing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QpGZbq3JgnD"
      },
      "outputs": [],
      "source": [
        "pred_holdouts = predict_model(tuned_lr)\n",
        "pred_holdouts.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3eTkE9efudjFZ60mzVLy6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}